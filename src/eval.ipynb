{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import pandas\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from keras.preprocessing import text, sequence\n",
    "from model import *\n",
    "import nltk\n",
    "from fasttext import load_model\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "#torch.distributed.init_process_group(backend=\"nccl\")\n",
    "from preprocess import *\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def load_DF(fname):\n",
    "    codes = ''\n",
    "    with open(fname, 'r',encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            codes += line\n",
    "    # print(codes)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "trainDF={}\n",
    "trainDF['doc'] = load_DF(f'../dataset/all.docstring')\n",
    "trainDF['code'] = load_DF(f'../dataset/all.code')\n",
    "#trainDF['ast'] = load_DF(f'../dataset/all.ast')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs = 200\n",
      "Batch size = 200\n",
      "Dataset = conala\n",
      "Model = REMODEL\n",
      "------------CRESS MODEL-------------\n"
     ]
    }
   ],
   "source": [
    "# Loading word embeddings\n",
    "def prepare_sequence(seq, seq_len, to_ix):\n",
    "    idxs_list = []\n",
    "    for seq_elem in seq:\n",
    "        idxs = []\n",
    "        for w in seq_elem.split():\n",
    "            geti = to_ix.get(w, 0)\n",
    "            if geti == 0:\n",
    "                print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "                print(w)\n",
    "                print(seq_elem)\n",
    "                print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            idxs.append(geti)\n",
    "        if len(idxs) > seq_len:\n",
    "            idxs = idxs[:seq_len]\n",
    "        while len(idxs) < seq_len:\n",
    "            idxs.append(0)\n",
    "        idxs.reverse()\n",
    "        idxs_list.append(idxs)\n",
    "    return torch.tensor(idxs_list, dtype=torch.long)\n",
    "\n",
    "def read_node_vec(fname):\n",
    "    node_embedding_index = {}\n",
    "    for i, line in enumerate(open('../word_vec/node.vec', 'r', encoding='utf-8')):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        values = line.split(\" \")\n",
    "        #print(\" \".join(values[:-128]))\n",
    "        node_embedding_index[\" \".join(values[:-128])] = np.asarray(values[-128:], dtype='float32')\n",
    "    return node_embedding_index\n",
    "\n",
    "def get_Graph_info(gs,embeddings_index, node_len, adj_len):\n",
    "    nodesl , adjsl = [], []\n",
    "    #nodesl = torch.Tensor(nodesl)\n",
    "    for g in gs:\n",
    "        g = eval(g)\n",
    "        G = nx.Graph()\n",
    "        G.add_weighted_edges_from(g)\n",
    "        nodes = G.nodes\n",
    "        # print(np.array(nx.adjacency_matrix(G).todense()))\n",
    "        if len(G.edges) != 0:\n",
    "            adj = np.array(nx.adjacency_matrix(G).todense())\n",
    "        l = adj_len-adj.shape[0]\n",
    "        if(l > 0):\n",
    "            adj = np.pad(adj,((0,l),(0,l)))\n",
    "        else:\n",
    "            adj = adj[:adj_len,:adj_len]\n",
    "        nfeat = []\n",
    "        for n in nodes:\n",
    "            vec = np.random.randn(128)\n",
    "            #vec = embeddings_index.get(n)\n",
    "            if vec is not None:\n",
    "                nfeat.append(vec)\n",
    "            else:\n",
    "                nfeat.append([0] * 128)\n",
    "        while len(nfeat) < node_len:\n",
    "            nfeat.append([0] * 128)\n",
    "        nodesl.append(nfeat[:100])\n",
    "        adjsl.append(adj[:])\n",
    "    return torch.Tensor(nodesl), torch.Tensor(adjsl)\n",
    "\n",
    "def create_embeddings(fname, embed_type):\n",
    "    embeddings_index = load_model(fname)\n",
    "\n",
    "    # create a tokenizer\n",
    "    token = code_tokenize(str_process(trainDF[embed_type]))\n",
    "    token = nltk.FreqDist(token)\n",
    "    sort = []\n",
    "    temp = sorted(token.items(), key=lambda x: x[1], reverse=True)\n",
    "    for key in temp:\n",
    "        sort.append(key[0])\n",
    "    word_index = {}\n",
    "    for i, word in enumerate(sort):\n",
    "        word_index[word] = i+1\n",
    "\n",
    "    # create token-embedding mapping\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    for i, word in enumerate(sort):\n",
    "        embedding_vector = np.array(embeddings_index.get_word_vector(word),dtype='float32')\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i+1] = embedding_vector\n",
    "    #print(word_index)\n",
    "    #print(embedding_matrix)\n",
    "    return word_index, embedding_matrix\n",
    "\n",
    "with open(\"../config.yml\", 'r') as config_file:\n",
    "    cfg = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "\n",
    "##############################################################\n",
    "#                     load dataset                           #\n",
    "##############################################################\n",
    "def read_json(dataset,dataset_type):\n",
    "    ret = []\n",
    "    if dataset_type == 'train':\n",
    "        for elem in dataset:\n",
    "            code = ' '.join(elem['code'])\n",
    "            doc = ' '.join(elem['doc'])\n",
    "            ast = ''.join(str(elem['ast']))\n",
    "            doc2 = ' '.join(elem['doc2'])\n",
    "            ret.append((code, ast, doc,doc2))\n",
    "            #ret.append((code, doc, doc2))\n",
    "    elif dataset_type == 'test':\n",
    "        for elem in dataset:\n",
    "            code = ' '.join(elem['code'])\n",
    "            doc = ' '.join(elem['doc'])\n",
    "            ast = ''.join(str(elem['ast']))\n",
    "            ret.append((code, ast, doc))\n",
    "            #ret.append((code, doc, code2))\n",
    "    return ret\n",
    "\n",
    "if cfg[\"dataset\"] == 'conala':\n",
    "    #train_dataset = json.load(open('../dataset/labelled_dataset_train.json', 'rb'))\n",
    "    test_dataset = json.load(open('../dataset/labelled_dataset_test.json', 'rb'))\n",
    "\n",
    "    #train_dataset = read_json(train_dataset,'train')\n",
    "    test_dataset = read_json(test_dataset,'test')\n",
    "    # codes_train, asts_train, docs_train, docs2_train = zip(*train_dataset)\n",
    "    codes_test, asts_test, docs_test = zip(*test_dataset)\n",
    "    # codes_train, docs_train, docs2_train = zip(*train_dataset)\n",
    "    #codes_test,  docs_test, codes2_test = zip(*test_dataset)\n",
    "\n",
    "    if cfg[\"model\"] == 'base':\n",
    "        # train_dataset = list(zip(codes_train, docs_train, docs2_train))\n",
    "        test_dataset = list(zip(codes_test, docs_test))\n",
    "    elif cfg[\"model\"] == 'REModel':\n",
    "        # train_dataset = list(zip(codes_train, docs_train, docs2_train))\n",
    "        test_dataset = list(zip(codes_test, docs_test))\n",
    "    elif cfg[\"model\"] == 'graph':\n",
    "        # train_dataset = list(zip(codes_train, asts_train, docs_train, docs2_train))\n",
    "        test_dataset = list(zip(codes_test, asts_test, docs_test))\n",
    "\n",
    "##############################################################\n",
    "#                     load dataset                           #\n",
    "##############################################################\n",
    "random_seed = cfg[\"random_seed\"]\n",
    "np.random.seed(random_seed)\n",
    "embedding_dim = cfg[\"embedding_dim\"]\n",
    "learning_rate = cfg[\"learning_rate\"]\n",
    "seq_len_doc = 0\n",
    "seq_len_code = 0\n",
    "hidden_size = cfg[\"hidden_size\"]\n",
    "dense_dim = cfg[\"dense_dim\"]\n",
    "output_dim = cfg[\"output_dim\"]\n",
    "num_layers_lstm = cfg[\"num_layers_lstm\"]\n",
    "use_cuda = cfg[\"use_cuda\"]\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "model_type = cfg[\"model\"]\n",
    "# n_iters = 4000\n",
    "# num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "# num_epochs = int(num_epochs)\n",
    "num_epochs = cfg[\"epochs\"]\n",
    "use_softmax_classifier = cfg[\"use_softmax_classifier\"]\n",
    "use_bin = cfg[\"use_bin\"]\n",
    "use_bidirectional = cfg[\"use_bidirectional\"]\n",
    "use_adam = cfg[\"use_adam\"]\n",
    "use_parallel = cfg[\"use_parallel\"]\n",
    "save_path = cfg[\"save_path\"]\n",
    "if use_cuda:\n",
    "    device_id = cfg[\"device_id\"]\n",
    "    torch.cuda.set_device(device_id)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Number of epochs = {num_epochs}\")\n",
    "print(f\"Batch size = {batch_size}\")\n",
    "print(f\"Dataset = {cfg['dataset']}\")\n",
    "print(f\"Model = {model_type.upper()}\")\n",
    "\n",
    "##############################################################\n",
    "#                     load dataset                           #\n",
    "##############################################################\n",
    "\n",
    "# Create word-index mapping\n",
    "word_to_ix_doc = {}\n",
    "word_to_ix_code = {}\n",
    "seq_len_code = seq_len_doc = seq_len_ast = 300\n",
    "load_var = False\n",
    "from model import *\n",
    "\n",
    "if cfg[\"dataset\"] == 'conala':\n",
    "    word_to_ix_doc, weights_matrix_doc = create_embeddings(f'../trained_models/doc.bin', 'doc')\n",
    "    word_to_ix_code, weights_matrix_code = create_embeddings(f'../trained_models/code.bin', 'code')\n",
    "    #word_to_ix_ast, weights_matrix_ast = create_ast_embeddings(f'../word_vec/ast.vec', 'ast')\n",
    "    weights_matrix_doc = torch.from_numpy(weights_matrix_doc)\n",
    "    weights_matrix_code = torch.from_numpy(weights_matrix_code)\n",
    "    #weights_matrix_ast = torch.from_numpy(weights_matrix_ast)\n",
    "elif cfg[\"dataset\"] == 'codesearchnet':\n",
    "    if not load_var:\n",
    "        word_to_ix_doc, weights_matrix_doc = create_embeddings(f'../{save_path}/doc_model.bin', 'doc')\n",
    "        word_to_ix_code, weights_matrix_code = create_embeddings(f'../{save_path}/code_model.bin', 'code')\n",
    "        word_to_ix_ast, weights_matrix_ast = create_embeddings(f'../{save_path}/ast_model.bin', 'ast')\n",
    "        weights_matrix_doc = torch.from_numpy(weights_matrix_doc)\n",
    "        weights_matrix_code = torch.from_numpy(weights_matrix_code)\n",
    "        weights_matrix_ast = torch.from_numpy(weights_matrix_ast)\n",
    "    else:\n",
    "        word_to_ix_doc, weights_matrix_doc = pickle.load(open(\"../variables/doc_var\",'rb'))\n",
    "        word_to_ix_code, weights_matrix_code = pickle.load(open(\"../variables/code_var\",'rb'))\n",
    "        word_to_ix_ast, weights_matrix_ast = pickle.load(open(\"../variables/ast_var\",'rb'))\n",
    "#node_embed_matrix = read_node_vec(\"\")\n",
    "if cfg['model'] == 'base':\n",
    "    print(\"------------BASE MODEL-------------\")\n",
    "    sim_model = BaseModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\n",
    "elif cfg['model'] == 'REModel':\n",
    "    print(\"------------CRESS MODEL-------------\")\n",
    "    sim_model = REModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\n",
    "elif cfg['model'] == 'graph':\n",
    "    print(\"------------GRAPH MODEL-------------\")\n",
    "    sim_model = GraphModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open(\"../config.yml\", 'r') as config_file:\n",
    "    cfg = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code):\n",
    "        super(BaseModel, self).__init__()\n",
    "        if cfg[\"encoder\"]=='Transformer':\n",
    "            self.doc_model = SelfAttnModel(weights_matrix_doc, hidden_size, dense_dim, output_dim)\n",
    "            self.code_model = SelfAttnModel(weights_matrix_code, hidden_size, dense_dim, output_dim)\n",
    "        elif cfg[\"encoder\"]=='LSTM':\n",
    "            self.doc_model = LSTMModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim)\n",
    "            self.code_model = LSTMModel(weights_matrix_code, hidden_size, num_layers_lstm, dense_dim, output_dim)\n",
    "        else:\n",
    "            print(\"Encoder must be Transformer or LSTM\")\n",
    "            exit()\n",
    "        self.dist = nn.modules.distance.PairwiseDistance(p=2, eps=1e-10)\n",
    "\n",
    "    def forward(self, doc_in, code_in):\n",
    "        doc_vector = self.doc_model(doc_in)\n",
    "        code_vector = self.code_model(code_in)\n",
    "        sim_score = 1.0-self.dist(doc_vector, code_vector)\n",
    "        if self.training:\n",
    "            return sim_score\n",
    "        else:\n",
    "            return doc_vector, code_vector\n",
    "class REModel(nn.Module):\n",
    "    def __init__(self, weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim,weights_matrix_code):\n",
    "        super(REModel, self).__init__()\n",
    "        if cfg[\"encoder\"] == 'Transformer':\n",
    "            self.doc_model = SelfAttnModel(weights_matrix_doc, hidden_size, dense_dim, output_dim)\n",
    "            self.code_model = SelfAttnModel(weights_matrix_code, hidden_size, dense_dim, output_dim)\n",
    "        elif cfg[\"encoder\"] == 'LSTM':\n",
    "            self.doc_model = LSTMModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim)\n",
    "            self.code_model = LSTMModel(weights_matrix_code, hidden_size, num_layers_lstm, dense_dim, output_dim)\n",
    "        else:\n",
    "            print(\"Encoder must be Transformer or LSTM\")\n",
    "            exit()\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        self.Re2Block = CrossBlock(weights_matrix_doc,weights_matrix_code,output_dim)\n",
    "        self.dist = nn.modules.distance.PairwiseDistance(p=2, eps=1e-10)\n",
    "        #self.pool = nn.MaxPool1d(2,stride=2)\n",
    "\n",
    "    def forward(self, doc_in, code_in):\n",
    "        doc_vector1 = self.doc_model(doc_in)\n",
    "        code_vector1 = self.code_model(code_in)\n",
    "\n",
    "        doc_vector2, code_vector2 = self.Re2Block(doc_in, code_in)\n",
    "        doc_vector = torch.cat((doc_vector1,doc_vector2),1)\n",
    "        code_vector = torch.cat((code_vector1, code_vector2),1)\n",
    "        # sim_score = 1.0 - self.dist(doc_vector, code_vector)\n",
    "        sim_score = self.cos(doc_vector, code_vector)\n",
    "        if self.training:\n",
    "            return sim_score\n",
    "        else:\n",
    "            return doc_vector, code_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GraphModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-4a6b5c38c821>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#sim_model = BaseModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m#sim_model = REModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msim_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGraphModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweights_matrix_doc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_layers_lstm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdense_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights_matrix_code\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0muse_parallel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0msim_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataParallel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msim_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'GraphModel' is not defined"
     ]
    }
   ],
   "source": [
    "#sim_model = BaseModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\n",
    "#sim_model = REModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\n",
    "sim_model = GraphModel(weights_matrix_doc, hidden_size, num_layers_lstm, dense_dim, output_dim, weights_matrix_code)\n",
    "if use_parallel:\n",
    "    sim_model = nn.DataParallel(sim_model)\n",
    "    sim_model = sim_model.module\n",
    "sim_model.load_state_dict(torch.load(f\"../{save_path}/sim_model_re_final_200\"))\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    sim_model.cuda()\n",
    "ret_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)\n",
    "ret1_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=500,\n",
    "                                          shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------EVAL CRESS----------------------\n",
      "vec calculation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9999 [00:12<33:40:10, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec calculation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9999 [00:24<33:40:14, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec calculation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9999 [00:36<33:43:09, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec calculation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/9999 [00:48<33:42:26, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec calculation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/9999 [01:07<37:25:54, 13.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-180901ac2d58>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m             \u001B[0mdoc_in\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdoc_in_ori\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcode_in\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m300\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m                 \u001B[0mdoc_in\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdoc_in\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m                 \u001B[0mcode_in\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcode_in\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m             \u001B[0mdoc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msim_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdoc_in\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcode_in\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"-----------------------EVAL CRESS----------------------\")\n",
    "mrr = 0\n",
    "count = 0\n",
    "r1 = 0\n",
    "r5 = 0\n",
    "r10 = 0\n",
    "ndcg = 0\n",
    "\n",
    "rank_list = []\n",
    "sim_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    codebase = []\n",
    "    docbase = []\n",
    "    for i, (code_seq, doc_seq) in enumerate(tqdm(ret_loader)):\n",
    "        doc_in_ori = prepare_sequence(doc_seq, seq_len_doc, word_to_ix_doc)\n",
    "        ranked_list = []\n",
    "        for j, (code_seqs, doc_seqs) in enumerate(ret1_loader):\n",
    "            code_in = prepare_sequence(code_seqs, seq_len_code, word_to_ix_code)\n",
    "            doc_in = doc_in_ori.expand(code_in.shape[0], 300)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                doc_in = doc_in.cuda()\n",
    "                code_in = code_in.cuda()\n",
    "            doc, code = sim_model(doc_in, code_in)\n",
    "            if j == 0:\n",
    "                docbase = doc\n",
    "                codebase = code\n",
    "            else:\n",
    "                docbase = torch.cat((docbase, doc), dim=0)\n",
    "                codebase = torch.cat((codebase, code), dim=0)\n",
    "\n",
    "        print(\"vec calculation complete\")\n",
    "        code_vecs = codebase\n",
    "        doc_vecs = docbase\n",
    "\n",
    "        docs = doc_vecs[i].expand((9999,-1))\n",
    "        score = F.cosine_similarity(docs, codebase, dim = -1).tolist()\n",
    "        for ite in range(0, len(score)):\n",
    "            score[ite] = (i, score[ite])\n",
    "        target = score[i]\n",
    "\n",
    "        ranked_list = sorted(score, key=lambda x:x[1], reverse=True)\n",
    "        rank = ranked_list.index(target) + 1\n",
    "        mrr += 1.0 / (rank)\n",
    "        if rank < 50:\n",
    "            ndcg += 1.0 / math.log2(rank + 1)\n",
    "        if rank == 1:\n",
    "            r1 += 1\n",
    "        if rank <= 5:\n",
    "            r5 += 1\n",
    "        if rank <= 10:\n",
    "            r10 += 1\n",
    "        count += 1\n",
    "print(count)\n",
    "mrr /= count\n",
    "r1 /= count\n",
    "r5 /= count\n",
    "r10 /= count\n",
    "ndcg /= count\n",
    "print(\"MRR = \", mrr)\n",
    "print(\"Recall@1 = \", r1)\n",
    "print(\"Recall@5 = \", r5)\n",
    "print(\"Recall@10 = \", r10)\n",
    "print(\"NDCG@50 = \", ndcg)\n",
    "df = pandas.DataFrame(rank_list, columns=['Query', 'Gold', 'Rank'])\n",
    "df.to_pickle(f\"../results/results_re_maxpool_{cfg['dataset']}.pkl\")\n",
    "with open(f\"../results/results_re_maxpool_{cfg['dataset']}.txt\", \"w\") as f:\n",
    "    f.write(f\"MRR = {mrr}\\n\")\n",
    "    f.write(f\"Recall@1 = {r1}\\n\")\n",
    "    f.write(f\"Recall@5 = {r5}\\n\")\n",
    "    f.write(f\"Recall@10 = {r10}\\n\")\n",
    "    f.write(f\"NDCG@50 = {ndcg}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------EVAL base----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:11,  1.72it/s]\n",
      "  0%|          | 0/9999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec calculation complete\n",
      "torch.Size([9999, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 176.85it/s]\n",
      "  0%|          | 19/9999 [00:00<00:56, 177.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.2556723162901669\n",
      "Recall@1 =  0.1627162716271627\n",
      "Recall@5 =  0.3422342234223422\n",
      "Recall@10 =  0.445044504450445\n",
      "NDCG@50 =  0.3455930053284242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 177.48it/s]\n",
      "  0%|          | 19/9999 [00:00<00:54, 184.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.24966198380198132\n",
      "Recall@1 =  0.1548154815481548\n",
      "Recall@5 =  0.33703370337033706\n",
      "Recall@10 =  0.44754475447544756\n",
      "NDCG@50 =  0.34115637315936687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 177.28it/s]\n",
      "  0%|          | 19/9999 [00:00<00:53, 188.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.25816700410290677\n",
      "Recall@1 =  0.1646164616461646\n",
      "Recall@5 =  0.34883488348834885\n",
      "Recall@10 =  0.4525452545254525\n",
      "NDCG@50 =  0.3487483621165133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:55<00:00, 181.21it/s]\n",
      "  0%|          | 36/9999 [00:00<00:57, 173.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.25149442512867637\n",
      "Recall@1 =  0.15761576157615761\n",
      "Recall@5 =  0.34153415341534155\n",
      "Recall@10 =  0.4456445644564456\n",
      "NDCG@50 =  0.34301960043745283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:58<00:00, 172.39it/s]\n",
      "  0%|          | 19/9999 [00:00<00:54, 182.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.2573926850651627\n",
      "Recall@1 =  0.1629162916291629\n",
      "Recall@5 =  0.3469346934693469\n",
      "Recall@10 =  0.45064506450645064\n",
      "NDCG@50 =  0.3481658943361748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:55<00:00, 180.19it/s]\n",
      "  0%|          | 38/9999 [00:00<00:53, 185.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.26065295651457987\n",
      "Recall@1 =  0.16671667166716672\n",
      "Recall@5 =  0.3513351335133513\n",
      "Recall@10 =  0.45344534453445345\n",
      "NDCG@50 =  0.35104284301276234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 177.39it/s]\n",
      "  0%|          | 37/9999 [00:00<00:54, 182.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.2611609127826912\n",
      "Recall@1 =  0.1634163416341634\n",
      "Recall@5 =  0.3576357635763576\n",
      "Recall@10 =  0.46224622462246223\n",
      "NDCG@50 =  0.3546684952041469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 177.05it/s]\n",
      "  0%|          | 19/9999 [00:00<00:54, 184.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.25294333172874656\n",
      "Recall@1 =  0.16061606160616063\n",
      "Recall@5 =  0.34003400340034\n",
      "Recall@10 =  0.43944394439443946\n",
      "NDCG@50 =  0.342815444873163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:56<00:00, 175.79it/s]\n",
      "  0%|          | 36/9999 [00:00<00:56, 177.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.26151273590963336\n",
      "Recall@1 =  0.16681668166816682\n",
      "Recall@5 =  0.3493349334933493\n",
      "Recall@10 =  0.45564556455645566\n",
      "NDCG@50 =  0.35298354153294875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [00:57<00:00, 172.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "MRR =  0.26071893228597304\n",
      "Recall@1 =  0.1636163616361636\n",
      "Recall@5 =  0.3536353635363536\n",
      "Recall@10 =  0.45514551455145513\n",
      "NDCG@50 =  0.35168502796255136\n",
      "MRR =  0.2569377283610518\n",
      "Recall@1 =  0.16238623862386242\n",
      "Recall@5 =  0.3468546854685469\n",
      "Recall@10 =  0.45073507350735065\n",
      "NDCG@50 =  0.3479878587963504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------EVAL base----------------------\")\n",
    "mrr = 0\n",
    "count = 0\n",
    "r1 = 0\n",
    "r5 = 0\n",
    "r10 = 0\n",
    "ndcg = 0\n",
    "\n",
    "rank_list = []\n",
    "sim_model.eval()\n",
    "with torch.no_grad():\n",
    "    for j, (code_seqs, doc_seqs) in tqdm(enumerate(ret1_loader)):\n",
    "        code_in = prepare_sequence(code_seqs,seq_len_code, word_to_ix_code)\n",
    "        doc_in = prepare_sequence(doc_seqs, seq_len_doc, word_to_ix_doc)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            doc_in = doc_in.cuda()\n",
    "            code_in = code_in.cuda()\n",
    "        doc, code = sim_model(doc_in, code_in)\n",
    "        if j == 0:\n",
    "            docbase = doc\n",
    "            codebase = code\n",
    "        else:\n",
    "            docbase = torch.cat((docbase, doc), dim=0)\n",
    "            codebase = torch.cat((codebase, code), dim=0)\n",
    "\n",
    "    print(\"vec calculation complete\")\n",
    "    code_vecs = codebase\n",
    "    doc_vecs = docbase\n",
    "    print(doc_vecs.shape)\n",
    "        # for i, vec in tqdm(enumerate(codebase)):\n",
    "        #      code_vecs.append((i, vec))\n",
    "        # print(\"code process complete\")\n",
    "        # for i, vec in tqdm(enumerate(docbase)):\n",
    "        #      doc_vecs.append((i, vec))\n",
    "        # print(\"doc process complete\")\n",
    "    for k in range(10):\n",
    "        imrr = 0\n",
    "        ir1 = 0\n",
    "        ir5 = 0\n",
    "        ir10 = 0\n",
    "        indcg = 0\n",
    "        count = 0\n",
    "        bootstrap_num_list = np.random.choice(9999,9999)\n",
    "        for i in tqdm(bootstrap_num_list):\n",
    "            doc = doc_vecs[i]\n",
    "            docs = doc.expand((9999,-1))\n",
    "            score = F.cosine_similarity(docs, codebase, dim = -1).tolist()\n",
    "            for ite in range(0, len(score)):\n",
    "                score[ite] = (i, score[ite])\n",
    "            target = score[i]\n",
    "\n",
    "            ranked_list = sorted(score, key=lambda x:x[1], reverse=True)\n",
    "            rank = ranked_list.index(target) + 1\n",
    "            imrr += 1.0 / (rank)\n",
    "            if rank < 50:\n",
    "                indcg += 1.0 / math.log2(rank + 1)\n",
    "            if rank == 1:\n",
    "                ir1 += 1\n",
    "            if rank <= 5:\n",
    "                ir5 += 1\n",
    "            if rank <= 10:\n",
    "                ir10 += 1\n",
    "            count += 1\n",
    "        print(count)\n",
    "        imrr /= count\n",
    "        ir1 /= count\n",
    "        ir5 /= count\n",
    "        ir10 /= count\n",
    "        indcg /= count\n",
    "        mrr += imrr\n",
    "        r1 += ir1\n",
    "        r5 += ir5\n",
    "        r10 += ir10\n",
    "        ndcg += indcg\n",
    "        print(\"MRR = \", imrr)\n",
    "        print(\"Recall@1 = \", ir1)\n",
    "        print(\"Recall@5 = \", ir5)\n",
    "        print(\"Recall@10 = \", ir10)\n",
    "        print(\"NDCG@50 = \", indcg)\n",
    "mrr /= 10\n",
    "r1 /= 10\n",
    "r5 /= 10\n",
    "r10 /= 10\n",
    "ndcg /= 10\n",
    "print(\"MRR = \", mrr)\n",
    "print(\"Recall@1 = \", r1)\n",
    "print(\"Recall@5 = \", r5)\n",
    "print(\"Recall@10 = \", r10)\n",
    "print(\"NDCG@50 = \", ndcg)\n",
    "df = pandas.DataFrame(rank_list, columns=['Query', 'Gold', 'Rank'])\n",
    "df.to_pickle(f\"../results/results_re_maxpool_{cfg['dataset']}.pkl\")\n",
    "with open(f\"../results/results_re_maxpool_{cfg['dataset']}.txt\", \"w\") as f:\n",
    "    f.write(f\"MRR = {mrr}\\n\")\n",
    "    f.write(f\"Recall@1 = {r1}\\n\")\n",
    "    f.write(f\"Recall@5 = {r5}\\n\")\n",
    "    f.write(f\"Recall@10 = {r10}\\n\")\n",
    "    f.write(f\"NDCG@50 = {ndcg}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001B[0m\u001B[01;34manaconda3\u001B[0m/                        \u001B[01;34mmetrinome\u001B[0m/\r\n",
      " \u001B[01;34mCLionProjects\u001B[0m/                    \u001B[01;34mMusic\u001B[0m/\r\n",
      " \u001B[01;34mDesktop\u001B[0m/                          \u001B[01;34mnltk_data\u001B[0m/\r\n",
      " \u001B[01;34mDocuments\u001B[0m/                        \u001B[01;34mPictures\u001B[0m/\r\n",
      " \u001B[01;34mDownloads\u001B[0m/                        \u001B[01;34mPublic\u001B[0m/\r\n",
      " \u001B[01;34meclipse\u001B[0m/                          \u001B[01;34mPycharmProjects\u001B[0m/\r\n",
      " \u001B[01;34meclipse-workspace\u001B[0m/                \u001B[01;34msensors\u001B[0m/\r\n",
      " \u001B[01;34mGames\u001B[0m/                            \u001B[01;34msimplecfg\u001B[0m/\r\n",
      " \u001B[01;34mgradle\u001B[0m/                           \u001B[01;34msnap\u001B[0m/\r\n",
      " \u001B[01;34midea-IC-211.7628.21\u001B[0m/              \u001B[01;34mSoftMaker\u001B[0m/\r\n",
      " \u001B[01;34mIdeaProjects\u001B[0m/                     \u001B[01;34mSteam\u001B[0m/\r\n",
      " \u001B[34;42mjava\u001B[0m/                            \u001B[01;34m'Sunlogin Files'\u001B[0m/\r\n",
      " java_error_in_pycharm_3892.log    \u001B[01;34mTemplates\u001B[0m/\r\n",
      " java_error_in_PYCHARM_69019.log   \u001B[37;44mthinclient_drives\u001B[0m/\r\n",
      " java_error_in_pycharm_.hprof      \u001B[01;34mVideos\u001B[0m/\r\n",
      " \u001B[01;34mJavaProjects\u001B[0m/                    \u001B[01;34m'VirtualBox VMs'\u001B[0m/\r\n",
      " \u001B[01;34mJLang\u001B[0m/                            \u001B[01;34mvmware\u001B[0m/\r\n",
      " \u001B[01;34mLibrary\u001B[0m/                         \u001B[01;34m'Vuze Downloads'\u001B[0m/\r\n",
      " \u001B[01;34mLLVM\u001B[0m/                             \u001B[01;34mWALA-master\u001B[0m/\r\n",
      " \u001B[01;34mllvm-project-llvmorg-12.0.0\u001B[0m/      \u001B[01;34mWALA-start\u001B[0m/\r\n",
      " \u001B[01;34mlocal_share\u001B[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}